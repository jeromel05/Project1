{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 21,
=======
   "execution_count": 15,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 22,
=======
   "execution_count": 2,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from UtilityFunctions import *"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 23,
=======
   "execution_count": 4,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "#deal with missing data (=-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x13af680b8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#corrcoef prod des vals normalisées à partir de la mat de correlation\n",
    "cov = np.cov(tX.T)\n",
    "#print(cov.shape, np.max(cov))\n",
    "corr = np.corrcoef(tX.T)\n",
    "#print(corr.shape, (corr))\n",
<<<<<<< Updated upstream
    "plt.imshow(corr, cmap='hot')"
=======
    "plt.imshow(corr, cmap='hot')\n",
    "res = np.where(corr > 0.95) #arbitrary threshold for strong correlation\n",
    "listOfCoordinates= list(zip(res[0], res[1]))\n",
    "listOfCoordinates = [cord for cord in listOfCoordinates if cord[0] != cord[1]] #remove diagonal\n",
    "listOfCoordinates = {tuple(sorted(t)): t for t in listOfCoordinates}#remove commutative elements\n",
    "for cord in listOfCoordinates:\n",
    "        print(cord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify strong correlations between the features listed above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca(tX)\n",
    "plt.scatter(X_pca[:,0],y, marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the first PCA component against the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm # To colour dots of scatter plot\n",
    "colors = cm.rainbow(y)\n",
    "plt.scatter(X_pca[:,0],X_pca[:,1], marker=\".\", color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of the first PCA component against the second PCA component. The dots are color labeled according to their output value y. Unfortunately, we notice that the clusters identified in the plot do not discriminate between the two output categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values positions :"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "1580052 0\n"
     ]
    }
   ],
   "source": [
    "tX2 = tX.copy()\n",
    "res = []\n",
    "for el in tX2.T:\n",
    "    res.append(el[el > -999])\n",
    "print(np.array(res).shape)\n",
    "\n",
    "mu = [np.mean(el) for el in res]\n",
    "sigma = [np.std(el) for el in res]\n",
    "\n",
    "for col, mu1, sigma1 in zip(tX2.T,mu,sigma):\n",
    "    col[col == -999] = np.random.normal(mu1, sigma1, np.sum([col == -999][0]))\n",
    "    \n",
    "print(np.sum(tX==-999), np.sum(tX2==-999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(250000, 30)\n",
      "(250000,) (150087, 23)\n",
      "(250000,) (150087, 23)\n",
      "[False False False False  True  True  True False False False False False\n",
      "  True False False False False False False False False False False False\n",
      " False False  True  True  True False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1720., 1658., 1705., 1662., 1847., 1904., 1892., 1803., 1686.,\n",
       "        1659., 1594., 1459., 1467., 1409., 1324., 1315., 1313., 1268.,\n",
       "        1133., 1159., 1089., 1041., 1118., 1144., 1165., 1158., 1079.,\n",
       "        1082., 1043., 1026., 1017., 1017., 1003.,  987.,  969.,  923.,\n",
       "         920.,  924.,  970.,  899.,  832.,  912.,  812.,  801.,  817.,\n",
       "         874.,  792.,  846.,  812.,  754.,  782.,  756.,  711.,  675.,\n",
       "         661.,  636.,  603.,  607.,  547.,  582.,  517.,  481.,  485.,\n",
       "         425.,  344.,  388.,  350.,  350.,  296.,  277.,  248.,  234.,\n",
       "         222.,  175.,  176.,  171.,  124.,  138.,  132.,   90.,   91.,\n",
       "          82.,   56.,   61.,   46.,   52.,   31.,   25.,   29.,   22.,\n",
       "          14.,   10.,   11.,   11.,    4.,    2.,    3.,    5.,    0.,\n",
       "           2.]),\n",
       " array([0.     , 0.08503, 0.17006, 0.25509, 0.34012, 0.42515, 0.51018,\n",
       "        0.59521, 0.68024, 0.76527, 0.8503 , 0.93533, 1.02036, 1.10539,\n",
       "        1.19042, 1.27545, 1.36048, 1.44551, 1.53054, 1.61557, 1.7006 ,\n",
       "        1.78563, 1.87066, 1.95569, 2.04072, 2.12575, 2.21078, 2.29581,\n",
       "        2.38084, 2.46587, 2.5509 , 2.63593, 2.72096, 2.80599, 2.89102,\n",
       "        2.97605, 3.06108, 3.14611, 3.23114, 3.31617, 3.4012 , 3.48623,\n",
       "        3.57126, 3.65629, 3.74132, 3.82635, 3.91138, 3.99641, 4.08144,\n",
       "        4.16647, 4.2515 , 4.33653, 4.42156, 4.50659, 4.59162, 4.67665,\n",
       "        4.76168, 4.84671, 4.93174, 5.01677, 5.1018 , 5.18683, 5.27186,\n",
       "        5.35689, 5.44192, 5.52695, 5.61198, 5.69701, 5.78204, 5.86707,\n",
       "        5.9521 , 6.03713, 6.12216, 6.20719, 6.29222, 6.37725, 6.46228,\n",
       "        6.54731, 6.63234, 6.71737, 6.8024 , 6.88743, 6.97246, 7.05749,\n",
       "        7.14252, 7.22755, 7.31258, 7.39761, 7.48264, 7.56767, 7.6527 ,\n",
       "        7.73773, 7.82276, 7.90779, 7.99282, 8.07785, 8.16288, 8.24791,\n",
       "        8.33294, 8.41797, 8.503  ]),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_val = np.zeros(tX.shape)\n",
    "print(missing_val.shape)\n",
    "missing_val[tX==-999] = 1\n",
    "total_cols = np.sum(missing_val, axis=0)/y.shape\n",
    "total_rows = np.sum(missing_val, axis=1)/np.shape(tX)[1]\n",
    "print(missing_val.shape)\n",
    "tX_reduced = tX[: ,total_cols < 0.5] #select only cols where less than 50% val missing and < 30% for rows\n",
    "tX_reduced = tX_reduced[total_rows<0.3, :] #and < 30% for rows\n",
    "y_reduced = y[total_rows<0.3]\n",
    "print(np.shape(total_rows), tX_reduced.shape)\n",
    "print(np.shape(total_rows>0.3), tX_reduced.shape)\n",
    "print(total_cols >0.5)\n",
    "\n",
    "tXcol = [el for el in tX[:,4] if el > -999]\n",
    "#plt.hist(tX[:,4])\n",
    "plt.hist(tXcol, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize\n",
    "x, mean_x, std_x = standardize(tX)\n",
    "\n",
    "#add offset\n",
    "tX = np.c_[np.ones(len(y)), x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/999): loss=0.3462390283558019, w0=340.48024424946476, w1=0.011877443209902866\n",
      "Gradient Descent(30/999): loss=0.34623902835580206, w0=340.4802442494641, w1=0.011877443209941937\n",
      "Gradient Descent(60/999): loss=0.34623902835580195, w0=340.4802442494632, w1=0.01187744321009351\n",
      "Gradient Descent(90/999): loss=0.3462390283558017, w0=340.4802442494624, w1=0.011877443210261959\n",
      "Gradient Descent(120/999): loss=0.3462390283558018, w0=340.4802442494615, w1=0.011877443210431972\n",
      "Gradient Descent(150/999): loss=0.34623902835580184, w0=340.48024424946067, w1=0.01187744321059006\n",
      "Gradient Descent(180/999): loss=0.3462390283558017, w0=340.4802442494602, w1=0.011877443210701444\n",
      "Gradient Descent(210/999): loss=0.34623902835580117, w0=340.4802442494602, w1=0.011877443210665256\n",
      "Gradient Descent(240/999): loss=0.3462390283558017, w0=340.4802442494602, w1=0.011877443210637554\n",
      "Gradient Descent(270/999): loss=0.34623902835580156, w0=340.4802442494602, w1=0.011877443210622623\n",
      "Gradient Descent(300/999): loss=0.3462390283558014, w0=340.4802442494602, w1=0.011877443210615133\n",
      "Gradient Descent(330/999): loss=0.34623902835580206, w0=340.4802442494602, w1=0.011877443210610444\n",
      "Gradient Descent(360/999): loss=0.3462390283558016, w0=340.4802442494602, w1=0.011877443210607222\n",
      "Gradient Descent(390/999): loss=0.3462390283558015, w0=340.4802442494602, w1=0.011877443210604239\n",
      "Gradient Descent(420/999): loss=0.34623902835580167, w0=340.4802442494602, w1=0.011877443210601843\n",
      "Gradient Descent(450/999): loss=0.34623902835580167, w0=340.4802442494602, w1=0.011877443210599591\n",
      "Gradient Descent(480/999): loss=0.34623902835580217, w0=340.4802442494602, w1=0.011877443210597314\n",
      "Gradient Descent(510/999): loss=0.34623902835580184, w0=340.4802442494602, w1=0.01187744321059547\n",
      "Gradient Descent(540/999): loss=0.3462390283558023, w0=340.4802442494602, w1=0.011877443210593485\n",
      "Gradient Descent(570/999): loss=0.3462390283558022, w0=340.4802442494602, w1=0.011877443210591964\n",
      "Gradient Descent(600/999): loss=0.34623902835580234, w0=340.4802442494602, w1=0.011877443210590111\n",
      "Gradient Descent(630/999): loss=0.3462390283558023, w0=340.4802442494602, w1=0.01187744321058907\n",
      "Gradient Descent(660/999): loss=0.34623902835580245, w0=340.4802442494602, w1=0.011877443210587896\n",
      "Gradient Descent(690/999): loss=0.34623902835580206, w0=340.4802442494602, w1=0.011877443210586647\n",
      "Gradient Descent(720/999): loss=0.34623902835580217, w0=340.4802442494602, w1=0.011877443210585816\n",
      "Gradient Descent(750/999): loss=0.3462390283558023, w0=340.4802442494602, w1=0.011877443210584994\n",
      "Gradient Descent(780/999): loss=0.346239028355802, w0=340.4802442494602, w1=0.011877443210583911\n",
      "Gradient Descent(810/999): loss=0.34623902835580195, w0=340.4802442494602, w1=0.011877443210583519\n",
      "Gradient Descent(840/999): loss=0.34623902835580206, w0=340.4802442494602, w1=0.011877443210582487\n",
      "Gradient Descent(870/999): loss=0.3462390283558024, w0=340.4802442494602, w1=0.011877443210582263\n",
      "Gradient Descent(900/999): loss=0.3462390283558021, w0=340.4802442494602, w1=0.011877443210582017\n",
      "Gradient Descent(930/999): loss=0.3462390283558023, w0=340.4802442494602, w1=0.011877443210581316\n",
      "Gradient Descent(960/999): loss=0.34623902835580267, w0=340.4802442494602, w1=0.01187744321058116\n",
      "Gradient Descent(990/999): loss=0.34623902835580267, w0=340.4802442494602, w1=0.011877443210581122\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(np.shape(tX2)[1])\n",
    "gamma = 0.0815\n",
    "max_iters = 1000\n",
    "final_loss, final_w = leastsquaresGD(y, tX2, w1, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/999): loss=0.4849793353419993, w0=-0.005, w1=-0.008159617848262054\n",
      "Gradient Descent(10/999): loss=0.5177063411479598, w0=0.001715090220154353, w1=0.003709212274579653\n",
      "Gradient Descent(20/999): loss=0.5741470693829509, w0=-0.014609399089541321, w1=-0.003840614239234227\n",
      "Gradient Descent(30/999): loss=0.5102547271800347, w0=-0.017647440324666457, w1=0.010696480082295392\n",
      "Gradient Descent(40/999): loss=0.5038878306120523, w0=-0.030988628907386642, w1=-0.006501066279462528\n",
      "Gradient Descent(50/999): loss=0.4910769425281217, w0=-0.034030834433708024, w1=-0.020185757361617804\n",
      "Gradient Descent(60/999): loss=0.5790441841078496, w0=-0.043702617097311186, w1=-0.011046139911278119\n",
      "Gradient Descent(70/999): loss=0.5369088200885644, w0=-0.035880475840421505, w1=-0.002081926825348251\n",
      "Gradient Descent(80/999): loss=0.5201115059624273, w0=-0.04242912432459718, w1=-0.006944939221021005\n",
      "Gradient Descent(90/999): loss=0.525622895007896, w0=-0.04005384121019525, w1=-0.006546880808366334\n",
      "Gradient Descent(100/999): loss=0.48355530587888634, w0=-0.040934963447078115, w1=-0.0056144756456363645\n",
      "Gradient Descent(110/999): loss=0.46017124112999336, w0=-0.04557373761519773, w1=-0.021133607097602796\n",
      "Gradient Descent(120/999): loss=0.4874445900977431, w0=-0.055726470122405905, w1=-0.035126273382288666\n",
      "Gradient Descent(130/999): loss=0.5012944405583211, w0=-0.050345502263288204, w1=-0.029626834404280062\n",
      "Gradient Descent(140/999): loss=0.47625442952092434, w0=-0.04591467643844258, w1=-0.02670309612541967\n",
      "Gradient Descent(150/999): loss=0.4494798688709942, w0=-0.0711163471937455, w1=-0.03317879058043135\n",
      "Gradient Descent(160/999): loss=0.4675668164189348, w0=-0.08466098266702772, w1=-0.0516460564722246\n",
      "Gradient Descent(170/999): loss=0.45322396408935145, w0=-0.07980785680161664, w1=-0.04170493621207923\n",
      "Gradient Descent(180/999): loss=0.43729851777093703, w0=-0.08832242173521725, w1=-0.04463613180833398\n",
      "Gradient Descent(190/999): loss=0.4696042860186026, w0=-0.08562506828034604, w1=-0.040338439790532164\n",
      "Gradient Descent(200/999): loss=0.44064092957046713, w0=-0.07923292027355035, w1=-0.03216271263141433\n",
      "Gradient Descent(210/999): loss=0.4368315050729333, w0=-0.08524879677162449, w1=-0.0299170130335246\n",
      "Gradient Descent(220/999): loss=0.440659522172713, w0=-0.07713349122243714, w1=-0.03680670420258002\n",
      "Gradient Descent(230/999): loss=0.46551231388923575, w0=-0.09154787133172076, w1=-0.04638628257354346\n",
      "Gradient Descent(240/999): loss=0.43873807003315396, w0=-0.09123671498623995, w1=-0.04690593565298834\n",
      "Gradient Descent(250/999): loss=0.5886075083666958, w0=-0.0686953775821733, w1=-0.029087091956189973\n",
      "Gradient Descent(260/999): loss=0.457288176225995, w0=-0.08080854070789271, w1=-0.04275399271329316\n",
      "Gradient Descent(270/999): loss=0.42760251477529304, w0=-0.09551995658308891, w1=-0.04166268411204843\n",
      "Gradient Descent(280/999): loss=0.42766239771466596, w0=-0.09886620249228004, w1=-0.05161452967872749\n",
      "Gradient Descent(290/999): loss=0.5201427922555676, w0=-0.07568217463221333, w1=-0.033397066020992544\n",
      "Gradient Descent(300/999): loss=0.44238285696419993, w0=-0.07784117521117781, w1=-0.02884165303127871\n",
      "Gradient Descent(310/999): loss=0.4334699741197649, w0=-0.09153339714042065, w1=-0.027176783258526894\n",
      "Gradient Descent(320/999): loss=0.4289578548246855, w0=-0.10016516834662396, w1=-0.039876234849132185\n",
      "Gradient Descent(330/999): loss=0.472700608078615, w0=-0.11883728109154927, w1=-0.05357393511409611\n",
      "Gradient Descent(340/999): loss=0.42601969477172547, w0=-0.10918945547480716, w1=-0.04538159136572852\n",
      "Gradient Descent(350/999): loss=0.43417663192672074, w0=-0.09896238419912443, w1=-0.03218509388408587\n",
      "Gradient Descent(360/999): loss=0.5627011933402911, w0=-0.10353275159120752, w1=-0.03884398600913056\n",
      "Gradient Descent(370/999): loss=0.52329804258359, w0=-0.11254317277096001, w1=-0.04570565429505056\n",
      "Gradient Descent(380/999): loss=0.4270800595115233, w0=-0.10390737917549883, w1=-0.03597931599281185\n",
      "Gradient Descent(390/999): loss=0.45579441545632154, w0=-0.08912510872523996, w1=-0.03727456260596531\n",
      "Gradient Descent(400/999): loss=0.4523306246739028, w0=-0.08378079428328154, w1=-0.030203770836132765\n",
      "Gradient Descent(410/999): loss=0.5120759144799203, w0=-0.08559690657337993, w1=-0.03278130550931281\n",
      "Gradient Descent(420/999): loss=0.4716034206987318, w0=-0.09873590161002295, w1=-0.03442877079041972\n",
      "Gradient Descent(430/999): loss=0.46951677636637373, w0=-0.08881581709946373, w1=-0.03311121927828794\n",
      "Gradient Descent(440/999): loss=0.46378031200235453, w0=-0.09156974542697362, w1=-0.026668029138746194\n",
      "Gradient Descent(450/999): loss=0.638222647992932, w0=-0.07527529086633719, w1=-0.016483341872053994\n",
      "Gradient Descent(460/999): loss=0.5146977461308996, w0=-0.09423437986462763, w1=-0.025909552968225065\n",
      "Gradient Descent(470/999): loss=0.47320944359396244, w0=-0.11395391434458711, w1=-0.035386159089598156\n",
      "Gradient Descent(480/999): loss=0.44933502011355325, w0=-0.09921508404664135, w1=-0.020426596039004343\n",
      "Gradient Descent(490/999): loss=0.4514498097975964, w0=-0.1076573006377989, w1=-0.017131372207170568\n",
      "Gradient Descent(500/999): loss=0.4352961000379478, w0=-0.10570367595931535, w1=-0.018686845311623526\n",
      "Gradient Descent(510/999): loss=0.43496016238837615, w0=-0.10336288604839715, w1=-0.010530591119895422\n",
      "Gradient Descent(520/999): loss=0.4662146714691425, w0=-0.0864469703066417, w1=-0.0049545305773308285\n",
      "Gradient Descent(530/999): loss=0.4262672885562492, w0=-0.10201806409513632, w1=-0.01663236252666853\n",
      "Gradient Descent(540/999): loss=0.42055889497230403, w0=-0.09466458544400402, w1=-0.012724371973809021\n",
      "Gradient Descent(550/999): loss=0.46544182245694066, w0=-0.10700281129340324, w1=-0.0234604367788654\n",
      "Gradient Descent(560/999): loss=0.42275523102254153, w0=-0.10310944740732152, w1=-0.02119063341075208\n",
      "Gradient Descent(570/999): loss=0.44700007252434293, w0=-0.10125604595312271, w1=-0.023549944576031885\n",
      "Gradient Descent(580/999): loss=0.42113678150764094, w0=-0.11894102701301876, w1=-0.031199740968760794\n",
      "Gradient Descent(590/999): loss=0.4694428259551854, w0=-0.11410589887126255, w1=-0.032185049361194124\n",
      "Gradient Descent(600/999): loss=0.48596039001231733, w0=-0.1442130879258743, w1=-0.044357797292841\n",
      "Gradient Descent(610/999): loss=0.4825473339506554, w0=-0.14618235874149071, w1=-0.0458113001324862\n",
      "Gradient Descent(620/999): loss=0.4533330852242419, w0=-0.15539135542770052, w1=-0.06255791322697346\n",
      "Gradient Descent(630/999): loss=0.47590601428351437, w0=-0.15371301800211157, w1=-0.06197230895720024\n",
      "Gradient Descent(640/999): loss=0.44354490129599605, w0=-0.13310440044675487, w1=-0.04583079572589496\n",
      "Gradient Descent(650/999): loss=0.4652716264231629, w0=-0.12564969877551968, w1=-0.034458842775666645\n",
      "Gradient Descent(660/999): loss=0.4431430713849942, w0=-0.13749774306692633, w1=-0.045246198526321155\n",
      "Gradient Descent(670/999): loss=0.4295139398116182, w0=-0.14231575803245927, w1=-0.04589322094294889\n",
      "Gradient Descent(680/999): loss=0.4380426229660571, w0=-0.12692157971735987, w1=-0.03996785816902091\n",
      "Gradient Descent(690/999): loss=0.4255112340266174, w0=-0.13695214682817708, w1=-0.04640049173916073\n",
      "Gradient Descent(700/999): loss=0.47282313550180716, w0=-0.1402563361732506, w1=-0.04079621634758432\n",
      "Gradient Descent(710/999): loss=0.4490853801197918, w0=-0.1548019919267458, w1=-0.05503846539040263\n",
      "Gradient Descent(720/999): loss=0.47587865198181195, w0=-0.16094874702568862, w1=-0.05532287453415595\n",
      "Gradient Descent(730/999): loss=0.4512405673326501, w0=-0.15573362572249183, w1=-0.05357701618027242\n",
      "Gradient Descent(740/999): loss=0.5383207773612645, w0=-0.1363419109369057, w1=-0.04239937035237505\n",
      "Gradient Descent(750/999): loss=0.47606795763200854, w0=-0.1356701248492633, w1=-0.03794862170410941\n",
      "Gradient Descent(760/999): loss=0.4577263288066254, w0=-0.1399779827736984, w1=-0.040907894479303084\n",
      "Gradient Descent(770/999): loss=0.4916060518222265, w0=-0.132771714110184, w1=-0.03581858573704568\n",
      "Gradient Descent(780/999): loss=0.4625590509230689, w0=-0.15976554668804338, w1=-0.05305130580072409\n",
      "Gradient Descent(790/999): loss=0.42836634176999694, w0=-0.15611487973512753, w1=-0.05244098676080612\n",
      "Gradient Descent(800/999): loss=0.4579947880700077, w0=-0.1498313434702496, w1=-0.05562880365293223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(810/999): loss=0.4200944192614319, w0=-0.14770687841246047, w1=-0.04775610719575398\n",
      "Gradient Descent(820/999): loss=0.4996613381586659, w0=-0.1299899272384051, w1=-0.027601312894983354\n",
      "Gradient Descent(830/999): loss=0.43063462045720313, w0=-0.141458309703284, w1=-0.03816884484622498\n",
      "Gradient Descent(840/999): loss=0.42096033564759416, w0=-0.15906807513783622, w1=-0.0483016932402563\n",
      "Gradient Descent(850/999): loss=0.42564881090656853, w0=-0.1411192361299688, w1=-0.03504174729863363\n",
      "Gradient Descent(860/999): loss=0.4227923413065378, w0=-0.13479020154973387, w1=-0.030163073099582542\n",
      "Gradient Descent(870/999): loss=0.43856005119281544, w0=-0.1479056237329925, w1=-0.038465632610282054\n",
      "Gradient Descent(880/999): loss=0.4366335254981862, w0=-0.12977738205743736, w1=-0.022076740677674164\n",
      "Gradient Descent(890/999): loss=0.41285899624511846, w0=-0.14350058374127986, w1=-0.02969513491181806\n",
      "Gradient Descent(900/999): loss=0.4396279513719277, w0=-0.15261433282978337, w1=-0.030661820762338768\n",
      "Gradient Descent(910/999): loss=0.5363128334445948, w0=-0.13590177103403736, w1=-0.033852871518793626\n",
      "Gradient Descent(920/999): loss=0.4214555898302287, w0=-0.137624802167652, w1=-0.03208669955515489\n",
      "Gradient Descent(930/999): loss=0.4205800087803186, w0=-0.13006014895396822, w1=-0.022202110292684683\n",
      "Gradient Descent(940/999): loss=0.4996056749145959, w0=-0.11585061726147806, w1=-0.008634812362479526\n",
      "Gradient Descent(950/999): loss=0.41345257922077766, w0=-0.14170703634399412, w1=-0.025628111158791298\n",
      "Gradient Descent(960/999): loss=0.4082385145316935, w0=-0.13829375996143345, w1=-0.02304420554529864\n",
      "Gradient Descent(970/999): loss=0.4213885297637025, w0=-0.1261416659213042, w1=-0.005086420204522317\n",
      "Gradient Descent(980/999): loss=0.45921719001674133, w0=-0.12437682220837555, w1=-0.003491478624240198\n",
      "Gradient Descent(990/999): loss=0.4302646635813361, w0=-0.13331909252510302, w1=-0.004972861912980863\n",
      "0.5034287810643492 [-0.12177371  0.07545476 -1.0407416  -0.11645851  0.10701323  0.12450128\n",
      "  0.02059902 -0.08516806  0.09050793 -0.13787191  0.27134441  0.01608071\n",
      "  0.12707743  0.067847    0.63286406  0.04804059  0.04393703  0.00265482\n",
      "  0.04836487  0.05382892  0.1125776   0.05095321 -0.05260492  0.05858832\n",
      " -0.07678389  0.04842192  0.0498225  -0.0656074   0.05073727  0.044046\n",
      " -0.2648915 ]\n"
     ]
    }
   ],
   "source": [
    "#Stochastic GD\n",
    "gamma = 0.005\n",
    "final_loss, final_w_sgd = leastsquaresSGD(y, tX2, initial_w, max_iters, gamma)\n",
    "print(final_loss, final_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n"
     ]
    }
   ],
   "source": [
    "#normal equations -> performs worse!!!\n",
    "print(tX2.dot(initial_w).shape)\n",
    "w1 = np.linalg.solve(np.dot(tX2.T,tX2),np.dot(tX2.T,y))#loss=0.3462325758854544"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/predicted.csv' # TODO: fill in desired name of output file for submission\n",
    "tX_test, mean_x, std_x = standardize(tX_test)\n",
    "tX_test  = np.c_[np.ones(tX_test.shape[0]), tX_test]\n",
    "y_pred = predict_labels(w1, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< Updated upstream
=======
    "lambdas = np.logspace(-5, 0, 15)\n",
    "rmse_rr = []\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "        w_rr,loss_rr = ridge_regression(y, tX, lambda_)\n",
    "        rmse_rr.append(rmse(loss_rr))\n",
    "\n",
    "plot_implementation(rmse_rr, lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### on polynomial version of the data set :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-5, 0, 15)\n",
    "rmse_rr_pol = []\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "        w_rr_pol,loss_rr_pol = ridge_regression(y, pX, lambda_)\n",
    "        rmse_rr_pol.append(rmse(loss_rr_pol))\n",
    "\n",
    "plot_implementation(rmse_rr_pol, lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and with split of test and train data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.logspace(-5, 0, 15)\n",
    "rmse_rr_pol_train = []\n",
    "rmse_rr_pol_test = []\n",
    "for ind, lambda_ in enumerate(lambdas):\n",
    "        w_rr_pol,loss_rr_pol_train = ridge_regression(ytrainpol,xtrainpol , lambda_)\n",
    "        rmse_rr_pol_train.append(rmse(loss_rr_pol_train))\n",
    "        rmse_rr_pol_test.append(rmse(compute_loss(ytestpol,xtestpol,w_rr_pol)))\n",
    "plot_train_test(rmse_rr_pol_train, rmse_rr_pol_test, lambdas)\n",
    "#JEROME: plot a l'air bizarre, exactement meme erreur pour test et train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Example - base mode\n",
    "gamma=0.5\n",
    "ws_1,log_likelihoods_1 = logistic_regression(rescale_y(y), tX, np.random.rand(tX.shape[1])/1000000,10, gamma)\n",
    "plt.scatter(rescale_predictions(compute_p(ws_1[-1],tX))[1:1000],y[1:1000], marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_2, log_likelihoods_2 = logistic_regression(rescale_y(y), tX, np.random.rand(tX.shape[1])/1000000,10,gamma)\n",
    "plt.scatter(rescale_predictions(compute_p(ws_2[-1],tX))[1:1000],y[1:1000], marker=\".\", color='b')\n",
    "np.linalg.norm(ws_1[-1]-ws_2[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##### Adding w0 to the model\n",
    "\n",
    "tX_w0 = adding_offset(tX)\n",
    "\n",
    "print(tX_w0[0:5,0:5],tX_w0.shape)\n",
    "\n",
    "ws_3,log_likelihoods_3 = logistic_regression(rescale_y(y), tX_w0, np.random.rand(tX_w0.shape[1])/1000000,10)\n",
    "\n",
    "plt.scatter(rescale_predictions(compute_p(ws_3[-1],tX_w0))[1:1000],y[1:1000], marker=\".\", color='b')\n",
    "\n",
    "ws_4,log_likelihoods_4 = logistic_regression(rescale_y(y), tX_w0, np.random.rand(tX_w0.shape[1])/1000000,10)\n",
    "\n",
    "plt.scatter(rescale_predictions(compute_p(ws_4[-1],tX_w0))[1:1000],y[1:1000], marker=\".\", color='b')\n",
    "\n",
    "np.linalg.norm(ws_3[-1]-ws_4[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train and test datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### replace -999 by average value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_corr = set_missing_explanatory_vars_to_mean(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_corr[:,1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_corr_pca = pca(tX_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cm.rainbow(y)\n",
    "plt.scatter(tX_corr_pca[:,0],tX_corr_pca[:,1], marker=\".\", color=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cm.rainbow(y[1:5000])\n",
    "plt.scatter(tX_corr_pca[1:5000,0],tX_corr_pca[1:5000,1], marker=\".\", color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find and delete outlier\n",
    "\n",
    "ind = np.arange(len(tX_corr_pca[:,0]))\n",
    "ind_outliers = ind[np.where(tX_corr_pca[:,0] < -50)] # find a suitable criterion, \n",
    "y_cleared = np.delete(y,ind_outliers)\n",
    "tX_corr_cleared = np.delete(tX_corr_pca,ind[np.where(tX_corr_pca[:,0] < -50)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_cleared.shape,tX_corr_cleared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_corr_cleared_w0 = adding_offset(tX_corr_cleared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_5,log_likelihoods_5 = logistic_regression(rescale_y(y_cleared), tX_corr_cleared_w0, np.random.rand(tX_corr_cleared_w0.shape[1])/1000000,10,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rescale_predictions(compute_p(ws_5[-1],tX_corr_cleared_w0))[1:1000],y_cleared[1:1000], marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_6, log_likelihoods_6 = logistic_regression(rescale_y(y_cleared), tX_corr_cleared_w0, np.random.rand(tX_corr_cleared_w0.shape[1])/1000000,10,gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rescale_predictions(compute_p(ws_6[-1],tX_corr_cleared_w0))[1:1000],y_cleared[1:1000], marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(ws_5[-1]-ws_6[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(ws_3[-1]-ws_5[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ws_3[-1],ws_5[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking into account patterns for the handling of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../data/test.csv\"\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "DATA_TRAIN_PATH = \"../data/train.csv\"\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that in both test and train data the same columns are full of gaps\n",
    "tX_mv = sum(tX == -999) # Array with columnwise count of faulty measurements in training data\n",
    "tX_mv[tX_mv > 0] = 1 \n",
    "tX_test_mv = sum(tX_test == -999) # Array with columnwise count of faulty measurements in test data\n",
    "tX_test_mv[tX_test_mv > 0] = 1\n",
    "\n",
    "np.linalg.norm(tX_mv-tX_test_mv) # = 0 means both training and test data have values missing only in the excact same explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 38114      0      0      0 177457 177457 177457      0      0      0\n",
      "      0      0 177457      0      0      0      0      0      0      0\n",
      "      0      0      0  99913  99913  99913 177457 177457 177457      0] [ 86488      0      0      0 402796 402796 402796      0      0      0\n",
      "      0      0 402796      0      0      0      0      0      0      0\n",
      "      0      0      0 227458 227458 227458 402796 402796 402796      0]\n"
     ]
    }
   ],
   "source": [
    "# Missing values don't appear to be random\n",
    "tX_mv = sum(tX == -999)\n",
    "tX_test_mv = sum(tX_test == -999)\n",
    "\n",
    "print(tX_mv,tX_test_mv) # Arrays with columnwise counts of faulty measurements in training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "ind = np.arange(tX.shape[1])\n",
    "tX_col_mv = tX[:,ind[np.where(tX_mv > 0)]]\n",
    "test = np.zeros(tX_col_mv.shape)\n",
    "test[np.where(tX_col_mv == -999)] = 1\n",
    "print(test[1:10,:]) # Extracted coulums that contain -999s. '1' represents missing value, '0' otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10000000000,  1000000000,   100000000,    10000000,     1000000,\n",
       "            100000,       10000,        1000,         100,          10,\n",
       "                 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.flip(np.power(10,np.arange(test.shape[1]),dtype=np.int64)) # Sleight of hand: matrix multiplication  with the following array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.11100011e+09, 1.11110001e+10, ...,\n",
       "       1.11100011e+09, 1.11111111e+09, 1.11111111e+10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(test,np.flip(np.power(10,np.arange(test.shape[1]),dtype=np.int64))) # The pattern of missing columns is represented by an array of numbers representing all samples in the usual order. The numbers are binary code for the matrix of the extracted columns just above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.00000000e+00, 1.11000111e+10, 1.11000111e+10,\n",
       "       1.11111111e+10, 1.11111111e+10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.dot(test,np.power(10,np.arange(test.shape[1]),dtype=np.int64))) # All the different configurations of the missing values. There are only six of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern of missing values and logistic regession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([8.75962595e-05, 4.10116242e-05, 6.90053350e-05, 1.61644555e-05,\n",
      "       3.95012255e-05, 4.07487347e-05, 4.56929609e-07, 8.86447135e-05,\n",
      "       3.06248427e-05, 3.37755667e-05, 5.63043950e-05, 6.55185704e-05,\n",
      "       7.47570473e-05, 6.96494976e-05, 6.84522668e-05, 7.90757569e-06,\n",
      "       6.50901944e-05, 5.21296732e-05, 3.38850496e-05, 2.98914945e-05,\n",
      "       5.76811735e-05, 8.18263294e-05, 3.79544194e-05, 9.79630539e-05,\n",
      "       4.13433984e-05, 4.92425032e-05, 8.98438239e-05, 5.70401470e-05,\n",
      "       3.78189061e-05, 4.30967773e-05]), array([-1.02320499e-03, -8.81000905e-03, -5.30117552e-03,  5.71852641e-03,\n",
      "       -5.34709979e-02,  1.10362073e-03, -2.04996223e-03,  5.98092092e-01,\n",
      "       -4.21215442e-03, -4.60126828e+00, -3.53785532e-01,  2.30619240e-01,\n",
      "        7.77418205e-01,  4.60919449e+00, -7.42897133e-03, -2.43018956e-04,\n",
      "        4.61603416e+00, -1.14193066e-02,  3.97780110e-03,  2.38983923e-03,\n",
      "        6.44832958e-03, -2.05836701e-03, -6.60259141e-01, -8.52246901e-03,\n",
      "        6.78510953e-03,  7.26185492e-03, -2.69577245e-03,  5.24226776e-03,\n",
      "       -3.66903397e-03,  4.60538794e+00]), array([-1.31087321e-03, -1.14322675e-02, -8.28080808e-03,  9.93640002e-03,\n",
      "       -1.89134401e-01,  2.26631202e-03,  6.65158031e-03,  8.88066830e-01,\n",
      "       -5.69858985e-03, -1.19484331e+00, -5.38158483e-01,  2.76432008e-01,\n",
      "        9.69970498e-01,  1.20379636e+00, -1.04204429e-02,  3.87247255e-04,\n",
      "        1.21538841e+00, -1.45727010e-02,  5.96634664e-03,  1.63979985e-03,\n",
      "        6.85334927e-03, -2.62270690e-03, -7.90809110e-01, -1.22547864e-02,\n",
      "        8.14432477e-03,  8.89602977e-03, -5.14895342e-03,  6.97323366e-03,\n",
      "       -3.98617625e-03,  1.19956714e+00]), array([-1.44068191e-03, -1.19510464e-02, -9.04748279e-03,  1.12202464e-02,\n",
      "       -2.57262794e-01,  2.84315860e-03,  9.91427043e-03,  9.66660500e-01,\n",
      "       -6.11387408e-03, -4.03609016e-02, -5.84958097e-01,  2.82376407e-01,\n",
      "        1.01395141e+00,  4.94759761e-02, -1.10051239e-02,  4.53313490e-04,\n",
      "        6.23374373e-02, -1.51735470e-02,  6.49788217e-03,  1.41747582e-03,\n",
      "        6.89213196e-03, -2.71018598e-03, -8.02493249e-01, -1.34099516e-02,\n",
      "        8.26426418e-03,  9.29163801e-03, -6.27451488e-03,  7.35584449e-03,\n",
      "       -3.98900593e-03,  4.50261248e-02])]\n",
      "[array([3.71804200e-05, 7.65128457e-05, 4.94101529e-05, 6.00858784e-05,\n",
      "       5.43061438e-05, 5.57402884e-05, 1.00437093e-05, 5.24452657e-05,\n",
      "       2.27567476e-05, 8.54278688e-05, 4.60533852e-05, 2.42575266e-05,\n",
      "       4.46858949e-05, 3.16707897e-05, 2.18328277e-05, 5.59869377e-05,\n",
      "       3.97973556e-05, 6.93970571e-05, 5.45890543e-05, 3.35691716e-05,\n",
      "       8.65998754e-06, 2.95920115e-05]), array([ 6.40088185e-03, -1.59012876e-02, -1.42174068e-02, -2.78717272e-03,\n",
      "        1.46028883e-01,  3.88845175e-03, -1.32321277e+01, -6.36779858e-01,\n",
      "        1.80235804e-01,  1.32375912e+01,  2.70027205e-03, -7.36859165e-03,\n",
      "        1.32561288e+01, -1.19962141e-02, -1.13383780e-03,  1.19896926e-03,\n",
      "        4.62797260e-03, -1.60013112e-03, -8.76773945e+01,  4.20985300e-04,\n",
      "       -9.95535664e-04,  1.00912501e+02]), array([ 9.52179587e-03, -1.87094305e-02, -2.35518335e-02, -8.40923250e-04,\n",
      "        3.40845140e-01,  4.96115140e-03, -1.45515060e+01, -1.02561602e+00,\n",
      "        1.92404284e-01,  1.45552699e+01,  5.67927318e-03, -9.45653259e-03,\n",
      "        1.45873861e+01, -1.71303874e-02, -2.14267691e-03, -2.06326274e-03,\n",
      "        5.39252875e-03, -1.96201049e-03, -1.01967593e+02,  4.45909401e-04,\n",
      "       -1.72298018e-03,  1.16522518e+02]), array([ 1.03841172e-02, -1.90884652e-02, -2.63304234e-02, -3.02886843e-04,\n",
      "        3.91460603e-01,  5.10463418e-03, -1.45414268e+01, -1.11685425e+00,\n",
      "        1.90576920e-01,  1.45447718e+01,  6.10065924e-03, -9.78020546e-03,\n",
      "        1.45804283e+01, -1.78184306e-02, -2.32328114e-03, -2.96509904e-03,\n",
      "        5.49049886e-03, -2.01169131e-03, -1.04880796e+02,  3.86360468e-04,\n",
      "       -1.88952492e-03,  1.19425645e+02])]\n",
      "[array([5.36555220e-05, 5.37537992e-05, 7.35722576e-05, 4.00131558e-06,\n",
      "       7.32190398e-05, 5.66514377e-05, 5.90934584e-05, 8.39141567e-05,\n",
      "       5.11135169e-06, 8.89884755e-06, 2.61590026e-05, 3.81806901e-05,\n",
      "       9.82931839e-05, 4.24778862e-05, 2.67262994e-05, 4.98320666e-05,\n",
      "       4.74583392e-05, 6.45296953e-05]), array([ 1.41129332e-02, -2.00030848e-02, -3.42247994e-02, -1.17165762e+02,\n",
      "        5.70915690e-01,  1.17162591e+02, -1.36426964e+01, -1.34450247e+00,\n",
      "        1.19362748e-03,  1.36436245e+01,  1.29769970e-03, -4.77748125e-06,\n",
      "        1.36808591e+01,  6.51827384e-03,  6.45821483e-04,  1.95249803e-03,\n",
      "       -7.83690933e-03,  5.64920446e-04]), array([ 2.20324498e-02, -1.84282767e-02, -6.09300884e-02, -2.22631603e+02,\n",
      "        1.09534705e+00,  2.22628597e+02, -1.67002000e+01, -2.48104602e+00,\n",
      "       -1.69324832e-02,  1.67003981e+01,  1.46947032e-03,  9.05908668e-04,\n",
      "        1.67670094e+01,  8.93723528e-03,  1.44457154e-03, -1.09837996e-02,\n",
      "       -1.21311978e-02,  1.27545299e-03]), array([ 2.50788784e-02, -1.82970321e-02, -7.51343797e-02, -2.52706032e+02,\n",
      "        1.35838724e+00,  2.52703800e+02, -1.77017851e+01, -3.08634225e+00,\n",
      "       -2.86021516e-02,  1.77005265e+01,  1.91133226e-03,  1.30420317e-03,\n",
      "        1.77884729e+01,  9.36710024e-03,  1.94884902e-03, -1.39156039e-02,\n",
      "       -1.37251076e-02,  1.40992047e-03])]\n",
      "[array([5.97306812e-05, 9.08157327e-05, 7.30561254e-05, 6.46378445e-05,\n",
      "       1.21679566e-05, 7.10855348e-05, 1.54786291e-06, 7.49345515e-06,\n",
      "       3.47078907e-05, 8.26543338e-05, 9.51539943e-05, 4.24613270e-06,\n",
      "       8.97428963e-05, 5.45893826e-05, 8.28987868e-05, 1.20228285e-05,\n",
      "       9.87487926e-06, 5.05267803e-06, 5.30641675e-05, 9.40815006e-05,\n",
      "       7.66949999e-05, 1.82113035e-05, 9.92593331e-05, 4.12761007e-05,\n",
      "       6.53178185e-05, 1.58914637e-05, 1.78522107e-05, 2.34744234e-05,\n",
      "       4.89231222e-06]), array([-1.87099592e-03, -2.68245836e-03,  6.28574381e-04, -1.13411797e-01,\n",
      "        1.24284283e-03, -3.41630154e-02,  3.11212994e-02,  7.73597573e-03,\n",
      "       -6.44266841e+00, -1.56764295e-01,  2.36439725e-03,  1.30153472e-01,\n",
      "        6.45093362e+00, -1.00960111e-02,  1.49193623e-03,  6.45253991e+00,\n",
      "       -6.63759749e-03, -9.78431987e-03,  2.38424142e-04,  2.01963128e-03,\n",
      "       -2.62244551e-03, -6.76770384e-01, -3.80189748e-03, -1.43246775e-02,\n",
      "       -8.12848196e-03, -4.13172675e-03,  4.66433989e-03,  3.02324237e-02,\n",
      "        6.44664884e+00]), array([-3.13844540e-03, -7.56452971e-03,  1.86455807e-03, -1.39711535e-01,\n",
      "        1.67780439e-03, -4.81879690e-02,  1.67051627e-01,  1.19314943e-02,\n",
      "       -2.58134183e+01, -3.21599911e-01, -8.65328254e-03,  2.96197723e-01,\n",
      "        2.58312310e+01, -2.61857950e-02, -4.19179747e-04,  2.58342110e+01,\n",
      "       -9.76382810e-03, -1.84969834e-02,  6.34971653e-04,  7.06889923e-03,\n",
      "       -4.45443108e-03, -1.11681842e+00, -6.05688197e-03, -2.71247089e-02,\n",
      "       -1.56310927e-02, -4.37526468e-03,  3.64906935e-03,  6.50738688e-02,\n",
      "        2.58191016e+01]), array([-4.27987011e-03, -1.51638807e-02,  2.68059832e-03, -1.40294539e-01,\n",
      "        1.85217718e-03, -5.00780336e-02,  3.95784427e-01,  1.42126735e-02,\n",
      "       -3.88436279e+01, -5.12915065e-01, -1.53677743e-02,  4.36930727e-01,\n",
      "        3.88683041e+01, -4.45653595e-02, -2.51919770e-04,  3.88768289e+01,\n",
      "       -4.63815151e-03, -2.50215540e-02,  1.71748371e-03,  1.48612835e-02,\n",
      "       -5.51650075e-03, -1.41686520e+00, -8.06892843e-03, -3.67298727e-02,\n",
      "       -2.06623259e-02, -4.92147961e-03, -5.82635981e-04,  9.31337729e-02,\n",
      "        3.88502943e+01])]\n",
      "[array([6.80187148e-05, 9.48100518e-05, 7.23472776e-05, 6.18131627e-06,\n",
      "       2.95153176e-05, 5.63172900e-05, 9.49517583e-05, 8.84822425e-05,\n",
      "       2.89140672e-05, 8.00657435e-05, 6.66287555e-05, 8.52218120e-05,\n",
      "       3.52684820e-05, 4.86906878e-05, 2.51443915e-05, 1.51592567e-05,\n",
      "       3.41764853e-05, 8.08585292e-07, 6.79475550e-06, 4.93849207e-05,\n",
      "       8.91618410e-05]), array([-8.37172761e-03,  1.56235871e-03, -9.91769100e-03, -3.25768533e-01,\n",
      "        5.02988059e-03,  5.87738511e+01, -6.74734258e-01,  1.95726463e-01,\n",
      "       -5.87817584e+01,  7.32553121e-03,  7.78019256e-03, -5.87441572e+01,\n",
      "        4.97326712e-03,  2.69987512e-03,  1.06393836e-02,  4.71241968e-03,\n",
      "       -3.53571718e-03, -5.56208183e+02, -5.01238668e-03, -4.51788514e-03,\n",
      "        4.97438566e+02]), array([-1.11382506e-02, -1.49377712e-03, -1.44903026e-02, -3.75185054e-01,\n",
      "        7.38217071e-03,  1.00553451e+02, -1.25835279e+00,  2.82194608e-01,\n",
      "       -1.00560155e+02,  2.03462462e-02,  1.95458338e-02, -1.00503110e+02,\n",
      "        1.07667930e-02,  5.06958642e-03,  1.69801770e-02,  1.26899241e-02,\n",
      "       -6.13408353e-03, -1.09013092e+03, -1.04144672e-02, -1.01752097e-02,\n",
      "        9.89584286e+02]), array([-1.17793458e-02, -7.19680549e-03, -1.65558725e-02, -2.68606616e-01,\n",
      "        8.50855352e-03,  1.27381951e+02, -1.75561687e+00,  3.18581185e-01,\n",
      "       -1.27386468e+02,  3.49303704e-02,  2.82167646e-02, -1.27315984e+02,\n",
      "        9.62722602e-03,  8.03514785e-03,  1.98897263e-02,  2.00964570e-02,\n",
      "       -7.66676635e-03, -1.42344335e+03, -1.43865094e-02, -1.44797161e-02,\n",
      "        1.29606973e+03])]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([8.88756531e-06, 4.04018710e-05, 8.16864709e-05, 2.78197653e-05,\n",
      "       8.61436089e-05, 1.32799225e-05, 9.85669112e-05, 6.02360238e-06,\n",
      "       7.51715359e-05, 6.30268455e-05, 4.49760922e-06, 6.13590727e-05,\n",
      "       2.24504993e-05, 3.44583114e-06, 7.48393106e-05, 9.79628465e-05,\n",
      "       2.85054344e-05]), array([-1.23051544e-02, -2.73078922e-03,  1.73287083e+02,  2.52395130e-02,\n",
      "       -1.73300842e+02,  1.93787081e+01, -8.16152048e-01,  1.20077323e+00,\n",
      "       -1.93899093e+01, -8.16305544e-04, -4.35673766e-03, -1.93364286e+01,\n",
      "        9.33993365e-03,  6.67774664e-04,  2.23657375e-02,  2.83910671e-03,\n",
      "       -1.78725623e-03]), array([-1.75437073e-02, -7.44464827e-03,  2.26892842e+02,  9.22051501e-02,\n",
      "       -2.26915982e+02,  4.02066868e+01, -1.58517885e+00,  1.81257201e+00,\n",
      "       -4.02205158e+01, -5.32829030e-03, -8.69142432e-03, -4.01307218e+01,\n",
      "        2.20735810e-02,  2.34104263e-03,  3.68033982e-02,  6.90716746e-03,\n",
      "       -3.55838564e-03]), array([-1.77164478e-02, -1.61705341e-02,  1.58668006e+02,  3.02111551e-01,\n",
      "       -1.58696224e+02,  5.69328203e+01, -2.41084584e+00,  2.17255741e+00,\n",
      "       -5.69478986e+01, -1.40067596e-02, -1.32261189e-02, -5.68269461e+01,\n",
      "        3.77657039e-02,  3.83465182e-03,  4.43889924e-02,  9.15268837e-03,\n",
      "       -5.07937457e-03])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x26fb1a2c908>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Splitting the data...\n",
    "tX_split, ind_row_groups, groups_mv_num = split_data_according_to_pattern_of_missing_values(tX) # => regroupement of the steps performed above\n",
    "y_split = split_y_according_to_pattern_of_missing_values(y, ind_row_groups)\n",
    "\n",
    "# ... and finding each subgroup's the optimal weights as well as predicting the y's of the training set using linear regression\n",
    "#     => condensed version is the function 'find_optimal_weights_pattern_mv'\n",
    "\n",
    "w_groups = [] # list to stock weights of subgroups\n",
    "y_pred = np.zeros([len(y)]) # initialize array y_pred\n",
    "\n",
    "for tX_group, y_group, ind_row_group in zip(tX_split,y_split,ind_row_groups) :\n",
    "    #print(tX_group, y_group, ind_row_group)\n",
    "    \n",
    "    # All-zero columns appear in the reduced data sets. They interfere with the calculation of the jacobean matrix.\n",
    "    # The corresponding weights are set to zero and the other weights are determined using a further reduced dataset without those columns.\n",
    "    \n",
    "    ind_col_non_zero = np.arange(len(tX_group[0,:]))[np.std(tX_group, axis = 0) > 0]\n",
    "    ws,log_likelihoods = logistic_regression(rescale_y(y_group), tX_group[:,ind_col_non_zero], np.random.rand(tX_group[:,ind_col_non_zero].shape[1])/10000,3)\n",
    "    print(log_likelihoods)\n",
    "    w_group = np.zeros(len(tX_group[0,:]))\n",
    "    w_group[ind_col_non_zero] = ws[-1]\n",
    "    w_groups.append(w_group)\n",
    "    y_pred[ind_row_group] = rescale_predictions(compute_p(w_group,tX_group))\n",
    "\n",
    "plt.scatter(y_pred[1:500],y[1:500], marker=\".\", color='b') # Plotting the predictions against the known values of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import matplotlib.cm as cm\n",
    "\n",
    "for tX_group, y_group in zip(tX_split,y_split):\n",
    "    tX_group_pca = pca(tX_group)\n",
    "    colors = cm.rainbow(y_group)\n",
    "    plt.scatter(tX_group_pca[:,0],tX_group_pca[:,1], marker=\".\", color=colors)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_split_test, ind_row_groups_test, groups_mv_num_test = split_data_according_to_pattern_of_missing_values(tX_test)\n",
    "\n",
    "\n",
    "''' Auxiliary function that calculates the predictions of each subgroup, joins them together in the right order\n",
    "    and rescales the predictions so that they lie between -1 and 1'''\n",
    "y_pred_test = predict_y_lr_weights_pattern_mv(ws_groups, tX_split_test,ind_row_groups_test,tX_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same with helper functions\n",
    "DATA_TRAIN_PATH = \"../data/train.csv/train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data...\n",
    "tX_split, ind_row_groups, groups_mv_num = split_data_according_to_pattern_of_missing_values(tX)\n",
    "y_split = split_y_according_to_pattern_of_missing_values(y, ind_row_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding interaction terms to the split data and calculating the optimal weights of each subgroup.\n",
    "ws_groups, y_pred = find_optimal_weights_pattern_mv(tX_split_test, ind_row_groups,y_split,tX.shape[0])\n",
    "plt.scatter(y_pred,y, marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred[ind_row_groups[4]][0:800],y[ind_row_groups[4]][0:800], marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../data/test.csv/test.csv\"\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_split_test, ind_row_groups_test, groups_mv_num_test = split_data_according_to_pattern_of_missing_values(tX_test)\n",
    "y_pred_test = predict_y_lr_weights_pattern_mv(ws_groups, tX_split_test,ind_row_groups_test,tX_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tX = y_pred\n",
    "y_pred_test_tX = y_pred_test\n",
    "ws_groups_tX = ws_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactions between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])\n",
    "print(add_interaction_terms(x),add_square_terms(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(add_higher_degree_terms(x, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best version so far: Pattern of missing values, interactions between variables and logistic regession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Squares of explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = \"../data/train.csv/train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data...\n",
    "tX_split, ind_row_groups, groups_mv_num = split_data_according_to_pattern_of_missing_values(tX)\n",
    "y_split = split_y_according_to_pattern_of_missing_values(y, ind_row_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding interaction terms to the split data and calculating the optimal weights of each subgroup.\n",
    "ws_groups, y_pred = find_optimal_weights_pattern_mv(add_exponential_terms_to_split_data(tX_split_test,2), ind_row_groups,y_split,tX.shape[0])\n",
    "plt.scatter(y_pred,y, marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred[ind_row_groups[4]][0:800],y[ind_row_groups[4]][0:800], marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../data/test.csv/test.csv\"\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_split_test, ind_row_groups_test, groups_mv_num_test = split_data_according_to_pattern_of_missing_values(tX_test)\n",
    "y_pred_test = predict_y_lr_weights_pattern_mv(ws_groups, add_exponential_terms_to_split_data(tX_split_test,2),ind_row_groups_test,tX_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_squares = y_pred\n",
    "y_pred_test_squares = y_pred_test\n",
    "ws_groups_squares = ws_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred_test_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cubic values of explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = \"../data/train.csv/train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data...\n",
    "tX_split, ind_row_groups, groups_mv_num = split_data_according_to_pattern_of_missing_values(tX)\n",
    "y_split = split_y_according_to_pattern_of_missing_values(y, ind_row_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding interaction terms to the split data and calculating the optimal weights of each subgroup.\n",
    "ws_groups, y_pred = find_optimal_weights_pattern_mv(add_exponential_terms_to_split_data(tX_split,3), ind_row_groups,y_split,tX.shape[0])\n",
    "plt.scatter(y_pred,y, marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred[ind_row_groups[4]][0:800],y[ind_row_groups[4]][0:800], marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../data/test.csv/test.csv\"\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_split_test, ind_row_groups_test, groups_mv_num_test = split_data_according_to_pattern_of_missing_values(tX_test)\n",
    "y_pred_test = predict_y_lr_weights_pattern_mv(ws_groups, add_exponential_terms_to_split_data(tX_split_test,3),ind_row_groups_test,tX_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cubic = y_pred\n",
    "y_pred_test_cubic = y_pred_test\n",
    "ws_groups_cubic = ws_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_no_conv = np.array([1,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_comb = y_pred_cubic\n",
    "for group in groups_no_conv:\n",
    "    y_pred_comb[ind_row_groups[group]] = y_pred_squares[ind_row_groups[group]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred_comb[ind_row_groups[1]][0:800],y[ind_row_groups[1]][0:800], marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups_no_conv:\n",
    "    y_pred_test[ind_row_groups_test[group]] = y_pred_test_squares[ind_row_groups_test[group]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interactions beween all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = \"../data/train.csv/train.csv\" # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data...\n",
    "tX_split, ind_row_groups, groups_mv_num = split_data_according_to_pattern_of_missing_values(tX)\n",
    "y_split = split_y_according_to_pattern_of_missing_values(y, ind_row_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding interaction terms to the split data and calculating the optimal weights of each subgroup.\n",
    "ws_groups, y_pred = find_optimal_weights_pattern_mv(add_interaction_terms_to_split_data(tX_split), ind_row_groups,y_split,tX.shape[0])\n",
    "plt.scatter(y_pred,y, marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding interaction terms to the split data and calculating the optimal weights of each subgroup.\n",
    "ws_groups, y_pred = find_optimal_weights_pattern_mv(add_interaction_terms_to_split_data(tX_split), ind_row_groups,y_split,tX.shape[0])\n",
    "plt.scatter(y_pred,y, marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_pred[ind_row_groups[4]][0:800],y[ind_row_groups[4]][0:800], marker=\".\", color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = \"../data/test.csv/test.csv\"\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_split_test, ind_row_groups_test, groups_mv_num_test = split_data_according_to_pattern_of_missing_values(tX_test)\n",
    "y_pred_test = predict_y_lr_weights_pattern_mv(ws_groups, add_interaction_terms_to_split_data(tX_split_test),ind_row_groups_test,tX_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_interact = y_pred\n",
    "y_pred_test_interact = y_pred_test\n",
    "ws_groups_interact = ws_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standartization - if one uses square and cubic values they might be larger of smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "\n",
    "    centered_data = x - np.mean(x, axis=0)\n",
    "    std_data = centered_data / np.std(centered_data, axis=0)\n",
    "    \n",
    "    return std_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/predicted.csv' # TODO: fill in desired name of output file for submission\n",
    "tX_test, mean_x, std_x = standardize(tX_test)\n",
    "tX_test  = np.c_[np.ones(tX_test.shape[0]), tX_test]\n",
    "y_pred = predict_labels(w1, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> Stashed changes
    "#implementer 10% du train set comme test set"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
